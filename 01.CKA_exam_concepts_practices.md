# CKA Exam Preparation

CKA = Certified Kubernetes Administrator</br>
Understand the CKA concept, prepare for the exam and practice, practice practices!

***

# Kubernetes Administration

**Disclaimer**: This is not likely a comprehensive list as the exam will be a moving target with the fast pace of k8s development - please make a pull request if there something wrong or that should be added, or updated in here.

Ensure you have the right version of Kubernetes documentation selected (e.g. v1.16 as of 20th Nov. 2019 exam) especially for API objects and annotations. This release removes several deprecated API's.  

## Exam Objectives

These are the exam objectives you review and understand in order to pass the test.

* [CNCF Exam Curriculum repository ](https://github.com/cncf/curriculum)


## [1. Core Concepts](https://kubernetes.io/docs/concepts/) 19%
<details> <summary> Details </summary>

* [Understand the Kubernetes API primitives](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/)
  * [concepts: Kubernetes Objects](https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/)
  * youtube: [Kubernetes Webinar Series - Kubernetes Architecture 101](https://www.youtube.com/watch?v=zeS6OyDoy78)
* [Understand the Kubernetes cluster architecture](https://kubernetes.io/docs/concepts/overview/components/)
  * youtube: [A Technical Overview of Kubernetes (CoreOS Fest 2015) by Brendan Burns](https://www.youtube.com/watch?v=WwBdNXt6wO4)
* [Understand Services and other network primitives](https://kubernetes.io/docs/concepts/services-networking/service/)
  * youtube: [Life of a Packet [I] - Michael Rubin, Google](https://www.youtube.com/watch?v=0Omvgd7Hg1I)
  * youtube: [The ins and outs of networking in Google Container Engine and Kubernetes (Google Cloud Next '17)](https://www.youtube.com/watch?v=y2bhV81MfKQ)

* Architecture diagram
![architecture-diagram](images/kubernetes-architecture.png)

    **Master Node**
    - kube-apiserver: front-end of the cluster that services REST operations and connects to the etcd database
    - kube-scheduler: schedules Pods on specific nodes based on labels, taints, and tolerations set for the Pods
    - etcd: a B+tree key-value store that keeps the current cluster state
    - kube-controller-manager: manages current state of the cluster 
    - cloud-controller-manager: interacts with outside cloud managers 
    - Different optionals add-ons: 
        - DNS
        - Dashboard
        - Cluster level resource monitoring 
        - Cluster level logging 

    **Worker Node**
    - kubelet: passes requests to the container engine to ensure that Pods are available 
    - kube-proxy: runs on every node and uses iptables to provide an interface to connect to Kubernetes components
    - container runtime: takes care of actually running the containers 
    - supervisord: monitors and guarantee the availability of the kubelet and docker processes
    - network agent: implements software defined network solutions, such as weave
    - logging: the CNCF Project Fluentd is used for unified logging in the cluster. A Fluentd agent must be installed on the K8s nodes. 


*  Example Nginx deployment:
```yaml
apiVersion: apps/v1beta2 # for versions before 1.8.0 use apps/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
```

**Controlling API Access**
- API access is regulated by RBAC
- In RBAC, user accounts are identified as a set of certificates associated to name, defined in ~/.kube/conf (or /etc/kubernetes/admin.conf)
  ```bash
  current-context: kubernetes-admin@kubernetes
  kind: Config
  users:
  - name: kubernetes-admin
    user:
      client-certificate-data: LS0t....
      client-key-data: LS0t...
  ```

- Kubernetes distinguishes between the concept of a user account and a service account for a number of reasons:

User accounts are for humans. Service accounts are for processes, which run in pods.
User accounts are intended to be global. Names must be unique across all namespaces of a cluster, future user resource will not be namespaced. Service accounts are namespaced.
Typically, a clusterÅfs User accounts might be synced from a corporate database, where new user account creation requires special privileges and is tied to complex business processes. Service account creation is intended to be more lightweight, allowing cluster users to create service accounts for specific tasks (i.e. principle of least privilege).
Auditing considerations for humans and service accounts may differ.
A config bundle for a complex system may include definition of various service accounts for components of that system. Because service accounts can be created ad-hoc and have namespaced names, such config is portable.


</details>


## [2. Installation, Configuration and Validation](https://github.com/kelseyhightower/kubernetes-the-hard-way/tree/f9486b081f8f54dd63a891463f0b0e783d084307) 12%
<details> <summary> Details </summary>

* Design a Kubernetes cluster
* [Install Kubernetes masters and nodes, including the use of TLS bootstrapping](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
* [Configure secure cluster communications](https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/)
* [Configure a Highly-Available Kubernetes cluster](https://kubernetes.io/docs/admin/high-availability/)
* [Know where to get the Kubernetes release binaries](https://kubernetes.io/docs/getting-started-guides/binary_release/#prebuilt-binary-release)
* [Provision underlying infrastructure to deploy a Kubernetes cluster](https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/f9486b081f8f54dd63a891463f0b0e783d084307/docs/01-infrastructure-gcp.md)
* [Choose a network solution](https://kubernetes.io/docs/concepts/cluster-administration/networking/)
* Choose your Kubernetes infrastructure configuration
* Run end-to-end tests on your cluster    
  * Some simple commands will cover most cases:
```
$ kubectl cluster-info
$ kubectl get nodes
$ kubectl get componentstatuses
$ kubectl get pods -o wide --show-labels --all-namespaces
$ kubectl get svc  -o wide --show-labels --all-namespaces
```

* Analyse end-to-end tests results.
* Install and use kubeadm to install, configure, and manage Kubernetes clusters.

* For more advanced end to end testing, which may not be covered on the exam, also see:
     * [End-To-End Testing in Kubernetes](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/e2e-tests.md)
     * [Using CNCF k8s conformance](https://github.com/cncf/k8s-conformance/blob/master/instructions.md)
     * [Heptio Sonobuoy Scanner](https://scanner.heptio.com/)

**Minikube architecture**
- Minikube is a minimum environment that manage to be functioned as Master and Worker node in single machine. 
- Minikube is good for CKAD practise, but a little difficult for CKA. 
- Architecture images: 

![minikube-architecture](images/minikube-architecture.jpeg)

- **Kubernetes Cluster Installation**
    1. Cluster Node Requirement
        - To setup a Kubernetes on-premise cluster, **kubeadm** is used
        - On this Lab, we use 1 control node (master) and 2 worker node
        - Install the CentOS 7.x Minimal
        - Turn off swap space as required by kubelet to work (comment out swap on /etc/fstab and reboot the machine)
        - Disable the firewall or open appropriate port in the firewall
    2. **ON ALL NODES**
        - Lab environment: 
            - Master/Control Plane
                - 2 CPU (minimum requirement, otherwise `kubeadm init` will error)
                - 2 GB Memory
                - master.example.com
            - Worker
                - 1 GB Memory
                - worker1.example.com
                - worker2.example.com
        - Disable swap
        - Docker Runtime
            - Use docker-ce (community-edition)
        - Install base components
            ```bash
            yum install -y vim git bash-completion
            ```
        - Install some component with script
            ```bash
            git clone https://github.com/fahmifahim/kubernetes-cka.git
            cd kubernetes-cka/installation
            chmod u+x ./setup-docker.sh
            ./setup-docker.sh
            chmod u+x ./setup-kubetools.sh
            ./setup-kubetools.sh
            ```
        - Disabling firewall
        - Setting up kubernetes repo
        - Set SELinux in permisive mode
        - Install `kubelet` `kubeadm` `kubectl`
        - Setup hostname resolving on /etc/hosts

            <details><summary>setup-docker.sh and setup-kubetools.sh</summary>

            - setup-docker.sh

            ```bash
            #!/bin/bash
            # script that runs 
            # https://kubernetes.io/docs/setup/production-environment/container-runtime

            yum install -y vim yum-utils device-mapper-persistent-data lvm2
            yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

            # notice that only verified versions of Docker may be installed
            # verify the documentation to check if a more recent version is available

            yum install -y docker-ce
            [ ! -d /etc/docker ] && mkdir /etc/docker

            cat > /etc/docker/daemon.json <<EOF
            {
            "exec-opts": ["native.cgroupdriver=systemd"],
            "log-driver": "json-file",
            "log-opts": {
                "max-size": "100m"
            },
            "storage-driver": "overlay2",
            "storage-opts": [
                "overlay2.override_kernel_check=true"
            ]
            }
            EOF

            cat >> /etc/hosts << EOF
            {
                192.168.11.14	master.example.com control master       # --> change this IP as your Lab environment
                192.168.11.15	worker1.example.com worker1             # --> change this IP as your Lab environment
                192.168.11.16	worker2.example.com worker2             # --> change this IP as your Lab environment
            }
            EOF

            mkdir -p /etc/systemd/system/docker.service.d

            systemctl daemon-reload
            systemctl restart docker
            systemctl enable docker

            systemctl disable --now firewalld
            ```

            - setup-kubetools.sh
            ```bash
            #!/bin/bash
            # kubeadm installation instructions as on
            # https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

            cat <<EOF > /etc/yum.repos.d/kubernetes.repo
            [kubernetes]
            name=Kubernetes
            baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
            enabled=1
            gpgcheck=1
            repo_gpgcheck=1
            gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
            EOF

            # Set SELinux in permissive mode (effectively disabling it)
            setenforce 0
            sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

            # disable swap (assuming that the name is /dev/centos/swap
            sed -i 's/^\/dev\/mapper\/centos-swap/#\/dev\/mapper\/centos-swap/' /etc/fstab
            swapoff /dev/mapper/centos-swap

            yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

            systemctl enable --now kubelet

            # Set iptables bridging
            cat <<EOF >  /etc/sysctl.d/k8s.conf
            net.bridge.bridge-nf-call-ip6tables = 1
            net.bridge.bridge-nf-call-iptables = 1
            EOF
            sysctl --system
            ```

            </details>

    3. **ON MASTER/CONTROL PLANE**
        - `kubeadm init`

            <details><summary> kubeadm init (logs) </summary>
            
            ```bash
            kubeadm init
            W0506 16:48:54.526194    9665 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]
            [init] Using Kubernetes version: v1.18.2
            [preflight] Running pre-flight checks
            [preflight] Pulling images required for setting up a Kubernetes cluster
            [preflight] This might take a minute or two, depending on the speed of your internet connection
            [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
            [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
            [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
            [kubelet-start] Starting the kubelet
            [certs] Using certificateDir folder "/etc/kubernetes/pki"
            [certs] Generating "ca" certificate and key
            [certs] Generating "apiserver" certificate and key
            [certs] apiserver serving cert is signed for DNS names [master.example.com kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.11.14]
            [certs] Generating "apiserver-kubelet-client" certificate and key
            [certs] Generating "front-proxy-ca" certificate and key
            [certs] Generating "front-proxy-client" certificate and key
            [certs] Generating "etcd/ca" certificate and key
            [certs] Generating "etcd/server" certificate and key
            [certs] etcd/server serving cert is signed for DNS names [master.example.com localhost] and IPs [192.168.11.14 127.0.0.1 ::1]
            [certs] Generating "etcd/peer" certificate and key
            [certs] etcd/peer serving cert is signed for DNS names [master.example.com localhost] and IPs [192.168.11.14 127.0.0.1 ::1]
            [certs] Generating "etcd/healthcheck-client" certificate and key
            [certs] Generating "apiserver-etcd-client" certificate and key
            [certs] Generating "sa" key and public key
            [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
            [kubeconfig] Writing "admin.conf" kubeconfig file
            [kubeconfig] Writing "kubelet.conf" kubeconfig file
            [kubeconfig] Writing "controller-manager.conf" kubeconfig file
            [kubeconfig] Writing "scheduler.conf" kubeconfig file
            [control-plane] Using manifest folder "/etc/kubernetes/manifests"
            [control-plane] Creating static Pod manifest for "kube-apiserver"
            [control-plane] Creating static Pod manifest for "kube-controller-manager"
            W0506 16:50:37.332345    9665 manifests.go:225] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"
            [control-plane] Creating static Pod manifest for "kube-scheduler"
            W0506 16:50:37.334387    9665 manifests.go:225] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"
            [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
            [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
            [apiclient] All control plane components are healthy after 35.529212 seconds
            [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
            [kubelet] Creating a ConfigMap "kubelet-config-1.18" in namespace kube-system with the configuration for the kubelets in the cluster
            [upload-certs] Skipping phase. Please see --upload-certs
            [mark-control-plane] Marking the node master.example.com as control-plane by adding the label "node-role.kubernetes.io/master=''"
            [mark-control-plane] Marking the node master.example.com as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
            [bootstrap-token] Using token: 121svj.8urd4tdpt7r51p5n
            [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
            [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
            [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
            [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
            [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
            [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
            [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
            [addons] Applied essential addon: CoreDNS
            [addons] Applied essential addon: kube-proxy

            Your Kubernetes control-plane has initialized successfully!

            To start using your cluster, you need to run the following as a regular user:

            mkdir -p $HOME/.kube
            sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
            sudo chown $(id -u):$(id -g) $HOME/.kube/config

            You should now deploy a pod network to the cluster.
            Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
            https://kubernetes.io/docs/concepts/cluster-administration/addons/

            Then you can join any number of worker nodes by running the following on each as root:

            kubeadm join 192.168.11.14:6443 --token 121svj.8urd4tdpt7r51p5n \
                --discovery-token-ca-cert-hash sha256:996d622a652b5ae512c1df35bf1560c252f0f70af8efee1a893849e5a7155231

            ```
            
            </details>

        - **Take a note of the `kubeadm join`** for the Token created

    4. **STARTING THE CLUSTER**
        - Create the client configuration as a regular user account
            ```bash
            su student
            mkdir -p $HOME/.kube
            sudo cp -l /etc/kubernetes/admin.conf $HOME/.kube/config
            sudo chown $(id -u):$(id -g) $HOME/.kube/config

            # Check the config file
            ls -l $HOME/.kube/config
               -rw-------. 1 student student 5453 May  6 17:00 config
            cat $HOME/.kube/config

            # (Optional) Your root user may also copy the config file to its directory
            sudo su -
            mkdir -p $HOME/.kube
            cp -l /etc/kubernetes/admin.conf $HOME/.kube/config
                --> Now your root user can call the kubectl command too
            ```
        - Verify by `kubectl cluster-info`
            ```bash
            $ kubectl cluster-info
            Kubernetes master is running at https://192.168.11.14:6443
            KubeDNS is running at https://192.168.11.14:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

            To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
            ```
        - `kubectl get nodes` (will give you not ready status at this point. it is normal)
            ```bash
            $ kubectl get nodes
            NAME                 STATUS     ROLES    AGE   VERSION
            master.example.com   NotReady   master   16m   v1.18.2
            ```
    5. **[Installing a Pod Network Add-on](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network)**
        - A Network Add-on must be installed for pods to communicate
        - CNI (Container Network Interface) which work with add-ons to implement networking
        - Look for an add-on that supports `network-policy` as well as RBAC
        - Common pod network plugin: 
            - Weave: a common ad-on for a CNI-enabled Kubernetes cluster
            - Flannel: a layer 3 IPV4 network between cluster nodes that can use several backend mechanism such as VXLAN
            - Calico: a layer 3 network solution that uses IP encapsulation and is used in Kubernetes, OpenStack, OpenShift, Docker, etc
            - AWS VPC: network plugin commonly used for AWS environment
        - Network plugin is installed from control plane (master node)
        - In our lab, we apply the Weave plugin: 
            ```bash
            # Install the network plugin from Master node
            $ kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
                serviceaccount/weave-net created
                clusterrole.rbac.authorization.k8s.io/weave-net created
                clusterrolebinding.rbac.authorization.k8s.io/weave-net created
                role.rbac.authorization.k8s.io/weave-net created
                rolebinding.rbac.authorization.k8s.io/weave-net created
                daemonset.apps/weave-net created    

            $ kubectl get pods --all-namespaces
                NAMESPACE     NAME                                         READY   STATUS    RESTARTS   AGE
                kube-system   coredns-66bff467f8-2vqrg                     1/1     Running   0          31m
                kube-system   coredns-66bff467f8-fnq7h                     1/1     Running   0          31m
                kube-system   etcd-master.example.com                      1/1     Running   0          31m
                kube-system   kube-apiserver-master.example.com            1/1     Running   0          31m
                kube-system   kube-controller-manager-master.example.com   1/1     Running   0          31m
                kube-system   kube-proxy-tbdzc                             1/1     Running   0          31m
                kube-system   kube-scheduler-master.example.com            1/1     Running   0          31m
                kube-system   weave-net-tp5b9                              2/2     Running   0          72s

            ! Make sure all the above pods are "Running" before you move forward to join the worker node to the cluster

            $ kubectl get nodes
                NAME                 STATUS   ROLES    AGE   VERSION
                master.example.com   Ready    master   33m   v1.18.2

            $ exit 

            ```
    6. **JOINING WORKER NODE**
        - Use the command from `kubeadm join` as we noted on the previous procedure
            ```bash
            kubeadm join 192.168.11.14:6443 --token 121svj.8urd4tdpt7r51p5n \
                --discovery-token-ca-cert-hash sha256:996d622a652b5ae512c1df35bf1560c252f0f70af8efee1a893849e5a7155231
            ```
        - Execute the `kubeadm join ...` at each worker nodes
            ```bash
            ssh worker1
                root@worker1's password:
                Last login: Wed May  6 17:30:47 2020 from master.example.com
            
            # Copy paste the kubeadm join
            kubeadm join 192.168.11.14:6443 --token 121svj.8urd4tdpt7r51p5n \
                --discovery-token-ca-cert-hash sha256:996d622a652b5ae512c1df35bf1560c252f0f70af8efee1a893849e5a7155231

            # Result: 
                W0506 17:32:39.026771    5170 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.
                [preflight] Running pre-flight checks
                [preflight] Reading configuration from the cluster...
                [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
                [kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.18" ConfigMap in the kube-system namespace
                [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
                [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
                [kubelet-start] Starting the kubelet
                [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

                This node has joined the cluster:
                * Certificate signing request was sent to apiserver and a response was received.
                * The Kubelet was informed of the new secure connection details.

                Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
            ```

            ```bash
            [student@master root]$ kubectl get nodes
                NAME                  STATUS   ROLES    AGE     VERSION
                master.example.com    Ready    master   51m     v1.18.2
                worker1.example.com   Ready    <none>   9m37s   v1.18.2
                worker2.example.com   Ready    <none>   77s     v1.18.2
            ```
    7. Check the `kubectl config view`
        ```bash
        $ kubectl config view
            apiVersion: v1
            clusters:
            - cluster:
                certificate-authority-data: DATA+OMITTED
                server: https://192.168.11.14:6443
            name: kubernetes
            contexts:
            - context:
                cluster: kubernetes
                user: kubernetes-admin
            name: kubernetes-admin@kubernetes
            current-context: kubernetes-admin@kubernetes
            kind: Config
            preferences: {}
            users:
            - name: kubernetes-admin
            user:
                client-certificate-data: REDACTED
                client-key-data: REDACTED    
        ```

</details>

## 3. Security 12%
<details> <summary> Details </summary>

* [Securing a kubernetes cluster](https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/)
    * youtube: [Building for Trust: How to Secure Your Kubernetes Cluster [I] - Alexander Mohr & Jess Frazelle](https://www.youtube.com/watch?v=YRR-kZub0cA)
* [Know how to configure authentication and authorization](https://kubernetes.io/docs/admin/authorization/rbac/)
  * [Access the api](https://kubernetes.io/docs/admin/accessing-the-api/)
  * [Authentication](https://kubernetes.io/docs/reference/access-authn-authz/authentication/)
  * [Authorization with RBAC](https://kubernetes.io/docs/admin/authorization/rbac/)
  * [Admission Control](https://kubernetes.io/docs/admin/admission-controllers/)
* [Understand Kubernetes security primitives]
  * [Pod Security Policy](https://kubernetes.io/docs/concepts/policy/pod-security-policy/)
    * [PSP and RBAC](https://github.com/kubernetes/examples/blob/master/staging/podsecuritypolicy/rbac/README.md)
* [Know to configure network policies](https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/)
  * [Blog: Kubernetes network policy](https://ahmet.im/blog/kubernetes-network-policy/)
  * [Katacoda Calico](https://www.katacoda.com/projectcalico/scenarios/calico)
* [Create and manage TLS certificates for cluster components](https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/)
* Work with images securely
* [Define security contexts](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/)
* [Secure persistent key value store](https://kubernetes.io/docs/concepts/configuration/secret/)

</details>

## [4. Networking](https://kubernetes.io/docs/concepts/cluster-administration/networking/) 11%
<details> <summary> Details </summary>

* [Understand the networking configuration on the cluster nodes](https://kubernetes.io/docs/concepts/cluster-administration/networking/)
* Understand Pod networking concepts
  * youtube: [The ins and outs of networking in Google Container Engine and Kubernetes (Google Cloud Next '17)](https://www.youtube.com/watch?v=y2bhV81MfKQ)
  * youtube: [Networking with Kubernetes](https://www.youtube.com/watch?v=WwQ62OyCNz4)
  * [Illustrated Guide To Kubernetes Networking by Tim Hockin](https://speakerdeck.com/thockin/illustrated-guide-to-kubernetes-networking)
* Understand service networking
  * youtube: [Life of a Packet [I] - Michael Rubin, Google](https://www.youtube.com/watch?v=0Omvgd7Hg1I)
* [Deploy and configure network load balancer](https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/)
* [Know how to use Ingress rules](https://kubernetes.io/docs/concepts/services-networking/ingress/)
* [Know how to configure and use the cluster DNS](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/)
* [Understand CNI](https://github.com/containernetworking/cni)
  * [More information on CNI](http://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/)

</details>

## 5. Cluster Maintenance 11%
<details> <summary> Details </summary>

* [Understand Kubernetes cluster upgrade process](https://kubernetes.io/docs/getting-started-guides/ubuntu/upgrades/)
    * Best resource upgrade is to watch [TGI Kubernetes 011: Upgrading to 1.8 with kubeadm](https://youtu.be/x9doB5eJWgQ)
* [Facilitate operating system upgrades](https://cloud.google.com/container-engine/docs/clusters/upgrade) #need review to make it more platform agnostic
* [Implement backup and restore methodologies](https://kubernetes.io/docs/getting-started-guides/ubuntu/backups/)
* Other: 
    * [Etcd management/backups/restore](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd)

</details>

## [6. Troubleshooting](https://kubernetes.io/docs/tasks/debug-application-cluster/troubleshooting/) 10%
<details> <summary> Details </summary>

* [Troubleshoot application failure](https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/)
  * [Application Introspection and Debugging](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application-introspection/)
  * [Services](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/)
* [Troubleshoot control plane failure](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/)
  * youtube [Kubernetes Day 2: Cluster Operations [I] - Brandon Philips, CoreOS](https://www.youtube.com/watch?v=U1zR0eDQRYQ)
  * Safaribooksonline: [https://www.safaribooksonline.com/library/view/oscon-2016-video/9781491965153/video246982.html](https://www.safaribooksonline.com/library/view/oscon-2016-video/9781491965153/video246982.html)
* [Troubleshoot worker node failure](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/)
* Troubleshoot networking

</details>

## [7. Storage](https://kubernetes.io/docs/concepts/storage/volumes/) 7%
<details> <summary> Details </summary>

* [Understand persistent volumes and know how to create them](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
* [Understand access modes for volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes)
* [Understand persistent volume claims primitive](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims)
* [Understand Kubernetes storage objects](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes)
* [Know how to configure applications with persistent storage](https://kubernetes.io/docs/tasks/configure-pod-container/configure-volume-storage/)

</details>

## 8. Application Lifecycle Management 8%
<details> <summary> Details </summary>

* [Understand Deployments and how to perform rolling updates and rollbacks](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)
* [Know various ways to configure applications](https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/)
* [Know how to scale applications](https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#scaling-your-application)
* Understand the primitives necessary to create a self-healing application

</details>

## 9. Scheduling 5%
<details> <summary> Details </summary>

* [Use label selectors to schedule Pods](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/)
* [Understand the role of DaemonSets](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)
* [Understand how resource limits can affect Pod scheduling](https://kubernetes.io/docs/tasks/administer-cluster/memory-default-namespace/)
* [Understand how to run multiple schedulers and how to configure Pods to use them](https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/)
* [Manually schedule a pod without a scheduler](https://kubernetes.io/docs/tasks/administer-cluster/static-pod/)
   If you require a pod to start on a specific node, you can specify this in POD spec.nodeName, that is what DaemonSets do.
* [Display scheduler events](https://stackoverflow.com/questions/28857993/how-does-kubernetes-scheduler-work/28874577#28874577)
  /var/log/kube-scheduler.log on the control/master node
  or use `kubectl describe` as in
```
  $kubectl describe pods <POD NAME UNDER Investigation>  | grep -A7 ^Events
```
* [Know how to configure the Kubernetes scheduler](https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/)

</details>

## [10. Logging/Monitoring](https://kubernetes.io/docs/concepts/cluster-administration/logging/) 5%
<details> <summary> Details </summary>

* [Understand how to monitor all cluster components](https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/)
* Understand how to monitor applications
* [Manage cluster component logs](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/#looking-at-logs)
  * Master
    * /var/log/kube-apiserver.log - API Server, responsible for serving the API
    * /var/log/kube-scheduler.log - Scheduler, responsible for making scheduling decisions
    * /var/log/kube-controller-manager.log - Controller that manages replication controllers
  * Worker Nodes
    * /var/log/kubelet.log - Kubelet, responsible for running containers on the node
    * /var/log/kube-proxy.log - Kube Proxy, responsible for service load balancing
* [Manage application logs](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs)
* Other: 
    * [Pod and Node metrics](https://kubernetes.io/docs/reference/kubectl/cheatsheet/#interacting-with-running-pods)
    * [Monitoring Kubernetes](https://www.datadoghq.com/blog/monitoring-kubernetes-era/)

</details>

***

## Practice Exam
* [CKA Practice Exam Environment](https://github.com/arush-sal/cka-practice-environment)
## Tips:

get familiar with:
* [kubectl explain](https://blog.heptio.com/kubectl-explain-heptioprotip-ee883992a243)
* [kubectl cheatsheet](https://kubernetes.io/docs/user-guide/kubectl-cheatsheet/)
* How to switch namespaces in Kubernetes?
```bash
kubectl config set-context --current --namespace=<namespace>
```
```bash
$ kubectl config current-contexts # check your current context 
$ kubectl config set-context <context-of-question> --namespace=<namespace-of-question>
$ kubectl config current-context 
$ kubectl config view 
$ kubectl config view | grep namespace
```
* When using kubectl for investigations and troubleshooting utilize the wide output it gives your more details
```
     $kubectl get pods -o wide‚Ä?--show-labels‚Ä?--all-namespaces
```
* In `kubectl` utilizie `--all-namespaces` to ensure deployments, pods, objects are on the right name space, and right desired state

* for events and troubleshooting utilize kubectl describe
```
     $kubectl describe pods <PODID>
```
* the '-o yaml' in conjuction with `--dry-run` allows you to create a manifest template from an imperative spec, combined with `--edit` it allows you to modify the object before creation
```
kubectl create service clusterip my-svc -o yaml --dry-run > /tmp/srv.yaml
kubectl create --edit -f /tmp/srv.yaml
```
## Do you want more?

- [Kubernauts resources list](https://docs.google.com/spreadsheets/d/10NltoF_6y3mBwUzQ4bcQLQfCE1BWSgUDcJXy-Qp2JEU/edit#gid=0)

#### Lab environment
```bash
#terapod
192.168.11.14	master.example.com
192.168.11.15	worker1.example.com
192.168.11.16	worker2.example.com


192 /et.168.11.5    putihfj
192.168.11.19   putihfj-back
192.168.11.25   vb-master.example.com
192.168.11.26   vb-worker1.example.com


#Command to turn on virtual machine by command
/usr/lib/vmware/bin/vmplayer /root/vmware/kb-worker1/kb-worker1.vmx
https://docs.vmware.com/en/VMware-Workstation-Player-for-Linux/15.0/com.vmware.player.linux.using.doc/GUID-BF62D91D-0647-45EA-9448-83D14DC28A1C.html

#But, I would recommend you Virtual Box ^^;

```
